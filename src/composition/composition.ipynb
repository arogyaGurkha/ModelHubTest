{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://webeng.kaist.ac.kr/webengpress/wp-content/uploads/2013/04/seunghyun.png\"\n",
    "response = requests.get(url)\n",
    "low_res_img = Image.open(\"/workspaces/ModelHubTest/src/composition/samples/0E96XUHZGSOP.jpg\")\n",
    "# low_res_img = low_res_img.resize((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a vehicle\"\n",
    "\n",
    "upscaled_image = pipeline(prompt=prompt, image=low_res_img).images[0]\n",
    "upscaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection, pipeline\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objdet_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "objdet_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = objdet_processor(images=upscaled_image, return_tensors=\"pt\")\n",
    "outputs = objdet_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sizes = torch.tensor([upscaled_image.size[::-1]])\n",
    "results = objdet_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "draw = ImageDraw.Draw(upscaled_image)\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    label_text = f\"{objdet_model.config.id2label[label.item()]}: {round(score.item(), 3)}\"\n",
    "    draw.rectangle(box, outline=\"red\", width=3)\n",
    "    draw.text((box[0], box[1]), label_text, fill=\"red\")\n",
    "    print(\n",
    "            f\"Detected {objdet_model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(upscaled_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-tiny-coco-instance\")\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-tiny-coco-instance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predicts class_queries_logits of shape `(batch_size, num_queries)`\n",
    "# and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n",
    "class_queries_logits = outputs.class_queries_logits\n",
    "masks_queries_logits = outputs.masks_queries_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can pass them to processor for postprocessing\n",
    "result = processor.post_process_instance_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "# we refer to the demo notebooks for visualization (see \"Resources\" section in the Mask2Former docs)\n",
    "predicted_instance_map = result[\"segmentation\"]\n",
    "predicted_instance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = \"tigeryi/imagenet-tiger\"\n",
    "\n",
    "classifier = pipeline(model=classifier_model, device=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"/workspaces/ModelHubTest/src/composition/samples/th-2550814735.jpg\"\n",
    "classifier(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timm\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\"edadaltocg/resnet18_cifar100\", pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top1_probabilities, top1_class_indices = torch.topk(output.softmax(dim=1) * 100, k=1)\n",
    "\n",
    "top1_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection, pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscaling(image, prompt=\"a vehicle\"):\n",
    "    model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
    "    pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
    "        model_id, torch_dtype=torch.float16\n",
    "    )\n",
    "    pipeline = pipeline.to(\"cuda\")\n",
    "\n",
    "    upscaled_image = pipeline(prompt=prompt, image=image).images[0]\n",
    "    return upscaled_image\n",
    "\n",
    "def segmentation(image, relevant_labels):\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\", revision=\"no_timm\")\n",
    "    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\", revision=\"no_timm\")\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Convert outputs (bounding boxes and class logits) to COCO API\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.6)[0]\n",
    "    print(f\"Detection Results: {results}\")\n",
    "\n",
    "    detected_patches = []\n",
    "\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        if str(label.item()) in relevant_labels:\n",
    "            print(\n",
    "                f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "                f\"{round(score.item(), 3)} at location {box}\"\n",
    "            )\n",
    "            # Extract the sub-patch from the image\n",
    "            left, top, right, bottom = box\n",
    "            sub_patch = image.crop((left, top, right, bottom))\n",
    "            detected_patches.append((sub_patch, score.item(), label.item(), box))\n",
    "\n",
    "\n",
    "    return detected_patches\n",
    "\n",
    "\n",
    "def classification(image):\n",
    "    model_id = \"apple/mobilevit-small\"\n",
    "    classifier = pipeline(model=model_id, device=0)\n",
    "    return classifier(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composition_runner(sampled_images):\n",
    "    relevant_labels = {\"2\": \"bicycle\", \"3\": \"car\", \"6\": \"bus\", \"7\": \"train\", \"8\": \"truck\"}\n",
    "    predictions = []\n",
    "    for image in sampled_images:\n",
    "        u_i = upscaling(image)\n",
    "        d_p = segmentation(u_i, relevant_labels)\n",
    "        for patch, score, label, box in d_p:\n",
    "            predictions.append(classification(patch))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def image_sampler(dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_patches(detected_patches):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, (patch, score, label, box) in enumerate(detected_patches):\n",
    "        plt.subplot(1, len(detected_patches), i + 1)\n",
    "        plt.imshow(patch)\n",
    "        plt.title(f\"Label: {label}, Score: {round(score, 2)}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def create_dataset(filepath, n_samples=5849):\n",
    "    dataset = load_dataset(\n",
    "        \"imagefolder\",\n",
    "        data_dir=filepath,\n",
    "        split=\"test\",\n",
    "    )\n",
    "    # dataset = dataset.shuffle(seed=42).select(range(n_samples))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_dataset = create_dataset(\"/workspaces/ModelHubTest/src/dataset/vehicles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d923b0914f974c89afdfe5e911a13c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdf7d6b5b094a1d9893e9b9bfda7ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"/workspaces/ModelHubTest/src/composition/samples/24CCSBI3QYFH.jpg\")\n",
    "upscaled_image = upscaling(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_image.save(\"/workspaces/ModelHubTest/src/composition/outputs/upscaled.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Results: {'scores': tensor([0.9994, 0.6095, 0.6447, 0.9385], grad_fn=<IndexBackward0>), 'labels': tensor([1, 4, 4, 4]), 'boxes': tensor([[ 3.2810e+02, -2.2661e-01,  4.8027e+02,  3.9414e+02],\n",
      "        [ 1.5074e+01,  2.1815e+02,  4.8614e+02,  5.0512e+02],\n",
      "        [ 1.4051e+01,  1.3868e+02,  4.8639e+02,  4.4360e+02],\n",
      "        [ 1.4478e+01,  1.3694e+02,  4.8621e+02,  5.0943e+02]],\n",
      "       grad_fn=<IndexBackward0>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevant_labels = {\"2\": \"bicycle\", \"3\": \"car\", \"6\": \"bus\", \"7\": \"train\", \"8\": \"truck\"}\n",
    "detected_patches = segmentation(upscaled_image, relevant_labels)\n",
    "visualize_patches(detected_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patch, score, label, box in detected_patches:\n",
    "    print(classification(patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(composition_runner(vehicle_dataset[:5][\"image\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_model_server'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_model_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLF_Models\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_model_server'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLF_Models:\n",
    "    def __init__(self):\n",
    "        self.models = pd.DataFrame()\n",
    "        self.inference_models = None\n",
    "        self.test_models = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"All Classification Models:\\n{self.models['model']},\\n\"\n",
    "            f\"Inference Models:\\n{self.inference_models['model']},\\n\"\n",
    "            f\"Test Models:\\n{self.test_models['model']},\\n\"\n",
    "        )\n",
    "    \n",
    "    def get_models_from_csv(self, filepath):\n",
    "        self.models = pd.read_csv(filepath)\n",
    "    \n",
    "    def random_sample_inference_models(self, count):\n",
    "        self.inference_models = self.models.sample(count)\n",
    "        self.test_models = self.models.drop(self.inference_models.index)\n",
    "\n",
    "clf_models = CLF_Models()\n",
    "clf_models.get_models_from_csv(\"/workspaces/ModelHubTest/src/composition/composition_classification_models.csv\")\n",
    "clf_models.random_sample_inference_models(10)\n",
    "print(clf_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'tractor', 'score': 0.38368913531303406},\n",
       "  {'label': 'thresher, thrasher, threshing machine',\n",
       "   'score': 0.3412572741508484},\n",
       "  {'label': 'harvester, reaper', 'score': 0.07035797089338303},\n",
       "  {'label': 'bulletproof vest', 'score': 0.033604104071855545},\n",
       "  {'label': 'jean, blue jean, denim', 'score': 0.018526067957282066}],\n",
       " [{'label': 'thresher, thrasher, threshing machine',\n",
       "   'score': 0.48355886340141296},\n",
       "  {'label': 'tractor', 'score': 0.38515520095825195},\n",
       "  {'label': 'harvester, reaper', 'score': 0.018105223774909973},\n",
       "  {'label': 'tow truck, tow car, wrecker', 'score': 0.015623060055077076},\n",
       "  {'label': 'trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi',\n",
       "   'score': 0.007327983621507883}],\n",
       " [{'label': 'passenger car, coach, carriage', 'score': 0.46890807151794434},\n",
       "  {'label': 'planetarium', 'score': 0.18813657760620117},\n",
       "  {'label': 'streetcar, tram, tramcar, trolley, trolley car',\n",
       "   'score': 0.05928593873977661},\n",
       "  {'label': 'bullet train, bullet', 'score': 0.03684035688638687},\n",
       "  {'label': 'prison, prison house', 'score': 0.029240326955914497}]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[[{'label': 'tractor', 'score': 0.38368913531303406}, {'label': 'thresher, thrasher, threshing machine', 'score': 0.3412572741508484}, {'label': 'harvester, reaper', 'score': 0.07035797089338303}, {'label': 'bulletproof vest', 'score': 0.033604104071855545}, {'label': 'jean, blue jean, denim', 'score': 0.018526067957282066}], [{'label': 'thresher, thrasher, threshing machine', 'score': 0.48355886340141296}, {'label': 'tractor', 'score': 0.38515520095825195}, {'label': 'harvester, reaper', 'score': 0.018105223774909973}, {'label': 'tow truck, tow car, wrecker', 'score': 0.015623060055077076}, {'label': 'trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi', 'score': 0.007327983621507883}], [{'label': 'passenger car, coach, carriage', 'score': 0.46890807151794434}, {'label': 'planetarium', 'score': 0.18813657760620117}, {'label': 'streetcar, tram, tramcar, trolley, trolley car', 'score': 0.05928593873977661}, {'label': 'bullet train, bullet', 'score': 0.03684035688638687}, {'label': 'prison, prison house', 'score': 0.029240326955914497}]]]\n",
    "test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

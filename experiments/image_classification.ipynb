{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyarrow as pa\n",
    "\n",
    "hf_token = dotenv_values(\".env\")['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, list_models, ModelCard, repo_exists, utils\n",
    "\n",
    "HF_HUB_DISABLE_PROGRESS_BARS=1\n",
    "# Configure a HfApi client\n",
    "hf_api = HfApi(\n",
    "    endpoint=\"https://huggingface.co\", # Can be a Private Hub endpoint.\n",
    "    token=hf_token, # Token is not persisted on the machine.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATTERN = re.compile(r\"fine-tuned version of \\[(.*?)\\]\")\n",
    "\n",
    "class BaseModelCache:\n",
    "    cache = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_name):\n",
    "        if model_name not in BaseModelCache.cache:\n",
    "            try:\n",
    "                BaseModelCache.cache[model_name] = ModelCard.load(model_name, ignore_metadata_errors=True)\n",
    "            except utils.RepositoryNotFoundError:\n",
    "                print(\"Repository not found for: \" + model_name)\n",
    "                BaseModelCache.cache[model_name] = None\n",
    "            except utils.EntryNotFoundError:\n",
    "                print(\"README not found for: \" + model_name)\n",
    "                BaseModelCache.cache[model_name] = None\n",
    "        return BaseModelCache.cache[model_name]\n",
    "\n",
    "def get_base_model_dataset(model_name):\n",
    "    \"\"\"Retrieve dataset information for a base model.\"\"\"\n",
    "    if model_name:\n",
    "        info = BaseModelCache.load(model_name)\n",
    "        if info:\n",
    "            return info.data.get(\"datasets\")\n",
    "    return None\n",
    "\n",
    "def extract_base_model_datasets(name, card_data):\n",
    "    \"\"\"Extract datasets for the base model.\"\"\"\n",
    "    base_model = card_data.get(\"base_model\")\n",
    "    if not base_model:\n",
    "        info = BaseModelCache.load(name)\n",
    "        match = BASE_MODEL_PATTERN.search(info.text)\n",
    "        base_model = match.group(1) if match else None\n",
    "\n",
    "    datasets = get_base_model_dataset(base_model)\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def extract_accuracy(results):\n",
    "    for result in results:\n",
    "        for metric in result.get(\"metrics\", []):\n",
    "            if metric.get(\"type\") == \"accuracy\":\n",
    "                accuracy_value = metric.get(\"value\")\n",
    "                if isinstance(accuracy_value, list) and accuracy_value:\n",
    "                    return float(accuracy_value[0])\n",
    "                elif isinstance(accuracy_value, (float, int)):\n",
    "                    return float(accuracy_value)\n",
    "    return 0.0\n",
    "\n",
    "def extract_dataset(name, card_data, results):\n",
    "    for result in results:\n",
    "        dataset = result.get(\"dataset\")\n",
    "        current_dataset = dataset.get(\"name\")\n",
    "        if current_dataset in [\"imagefolder\", \"image_folder\"]:\n",
    "            datasets = extract_base_model_datasets(name, card_data) or []\n",
    "            return [current_dataset, *datasets]\n",
    "        else:\n",
    "            return [current_dataset]\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_valid_card_data(name, card_data):\n",
    "    necessary_keys = [\"task\", \"dataset\", \"metrics\"]\n",
    "    model_index = card_data.get(\"model-index\", [])\n",
    "    if not model_index:\n",
    "        return False, None, None\n",
    "\n",
    "    for entry in model_index:\n",
    "        results = entry.get(\"results\", [])\n",
    "        if not results:\n",
    "            return False, None, None\n",
    "        for result in results:\n",
    "            if not all(key in result for key in necessary_keys):\n",
    "                return False, None, None\n",
    "    return True, extract_accuracy(results), extract_dataset(name, card_data, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Invalid model-index. Not loading eval results into CardData.\n"
     ]
    }
   ],
   "source": [
    "models = hf_api.list_models(task=\"automatic-speech-recognition\", cardData=True,)\n",
    "\n",
    "processed_models = []\n",
    "accuracy_values = []\n",
    "datasets = []\n",
    "for model in models:\n",
    "    if model.card_data:\n",
    "        card_data = yaml.safe_load(str(model.card_data))\n",
    "        is_valid, accuracy, dataset = is_valid_card_data(model.id, card_data)\n",
    "        if is_valid:\n",
    "            model.card_data = card_data\n",
    "            processed_models.append(model)\n",
    "            accuracy_values.append(accuracy or 0)\n",
    "            datasets.append(dataset or None)\n",
    "\n",
    "df = pd.DataFrame({'model': processed_models, 'accuracy': accuracy_values, 'dataset': datasets})\n",
    "df = df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"speech_models.csv\")\n",
    "df.to_pickle(\"speech_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>ModelInfo(id='ozzyonfire/bird-species-classifi...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Bird Species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>ModelInfo(id='chriamue/bird-species-classifier...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Bird Species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>imagefolder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>imagenet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>imagenet-21k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>ModelInfo(id='sbottazziunsam/10-classifier-fin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imagenet-1k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>ModelInfo(id='sbottazziunsam/9-classifier-fine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imagefolder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>ModelInfo(id='sbottazziunsam/9-classifier-fine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chest X-rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>ModelInfo(id='debajyotidasgupta/convnextv2-bas...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imagefolder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>ModelInfo(id='debajyotidasgupta/convnextv2-bas...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imagenet-22k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  model  accuracy  \\\n",
       "2939  ModelInfo(id='ozzyonfire/bird-species-classifi...      96.8   \n",
       "1253  ModelInfo(id='chriamue/bird-species-classifier...      96.8   \n",
       "2639  ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...       1.0   \n",
       "2639  ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...       1.0   \n",
       "2639  ModelInfo(id='alirzb/S1_M1_R1_beit_42507336', ...       1.0   \n",
       "...                                                 ...       ...   \n",
       "3009  ModelInfo(id='sbottazziunsam/10-classifier-fin...       0.0   \n",
       "3007  ModelInfo(id='sbottazziunsam/9-classifier-fine...       0.0   \n",
       "3007  ModelInfo(id='sbottazziunsam/9-classifier-fine...       0.0   \n",
       "2742  ModelInfo(id='debajyotidasgupta/convnextv2-bas...       0.0   \n",
       "2742  ModelInfo(id='debajyotidasgupta/convnextv2-bas...       0.0   \n",
       "\n",
       "           dataset  \n",
       "2939  Bird Species  \n",
       "1253  Bird Species  \n",
       "2639   imagefolder  \n",
       "2639      imagenet  \n",
       "2639  imagenet-21k  \n",
       "...            ...  \n",
       "3009   imagenet-1k  \n",
       "3007   imagefolder  \n",
       "3007  chest X-rays  \n",
       "2742   imagefolder  \n",
       "2742  imagenet-22k  \n",
       "\n",
       "[6209 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explode = df.explode(\"dataset\")\n",
    "df_explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ./data/games-ad-0306\n",
      "Dataset: ./mgr/dataset/HF_DS\n",
      "Dataset: 1aurent/Kather-texture-2016\n",
      "Dataset: 1aurent/LC25000\n",
      "Dataset: Beans\n",
      "Dataset: Bird Species\n",
      "Dataset: CIFAR-10\n",
      "Dataset: CIFAR-100\n",
      "Dataset: CIFAR100\n",
      "Dataset: Camelyon16[Meta]\n",
      "Dataset: CelebA-faces\n",
      "Dataset: Cifar10\n",
      "Dataset: Cifar100\n",
      "Dataset: Dataset_points_durs_v1\n",
      "Dataset: Dog Food\n",
      "Dataset: Falah/Alzheimer_MRI\n",
      "Dataset: FastJobs/Visual_Emotional_Analysis\n",
      "Dataset: HumanEval\n",
      "Dataset: Human_Action_Recognition\n",
      "Dataset: Indian-Food-Images\n",
      "Dataset: JLB-JLB/seizure_eeg_greyscale_224x224_6secWindow\n",
      "Dataset: KTH-TIPS2-b\n",
      "Dataset: MNIST\n",
      "Dataset: Matthijs/snacks\n",
      "Dataset: New Plant Diseases Dataset\n",
      "Dataset: RiniPL/Dementia_Dataset\n",
      "Dataset: SVHN\n",
      "Dataset: TCGA-BRCA\n",
      "Dataset: action_class\n",
      "Dataset: agent_action_class\n",
      "Dataset: amazonian_fish_classifier_data\n",
      "Dataset: arabic-handwritten-characters\n",
      "Dataset: bazyl/GTSRB\n",
      "Dataset: beans\n",
      "Dataset: bird-data\n",
      "Dataset: bird_species_dataset\n",
      "Dataset: blurry images\n",
      "Dataset: brain-tumor-collection\n",
      "Dataset: breast-invasive-ductal-carcinoma-cancer\n",
      "Dataset: catbreed\n",
      "Dataset: cats_vs_dogs\n",
      "Dataset: chbh7051/driver-drowsiness-detection\n",
      "Dataset: chbh7051/vit-base-driver-drowsiness-detection\n",
      "Dataset: chest X-rays\n",
      "Dataset: chest-xray-classification\n",
      "Dataset: chestxrayclassification\n",
      "Dataset: cifar10\n",
      "Dataset: cifar10-lt\n",
      "Dataset: cifar100\n",
      "Dataset: cifar10_quality_drift\n",
      "Dataset: codenames-pictures\n",
      "Dataset: croupier-mtg-dataset\n",
      "Dataset: custom_dataset\n",
      "Dataset: custom_dataset_augmented\n",
      "Dataset: d071696/scraps1\n",
      "Dataset: defect\n",
      "Dataset: dfl\n",
      "Dataset: doctype_v1\n",
      "Dataset: ernie-ai/image-text-examples-ar-cn-latin-notext\n",
      "Dataset: eurosat\n",
      "Dataset: eurosat-rgb\n",
      "Dataset: fair_face\n",
      "Dataset: farleyknight/roman_numerals\n",
      "Dataset: fashion_mnist\n",
      "Dataset: fashion_mnist_quality_drift\n",
      "Dataset: finetuned-cifar10-lt\n",
      "Dataset: fl_image_category_ds\n",
      "Dataset: food-101\n",
      "Dataset: food101\n",
      "Dataset: food_images_classification\n",
      "Dataset: fsuarez/autotrain-data-logo-identifier\n",
      "Dataset: huggan/wikiart\n",
      "Dataset: image-classification-yenthienviet\n",
      "Dataset: image_folder\n",
      "Dataset: imagefolder\n",
      "Dataset: imagenet\n",
      "Dataset: imagenet-1k\n",
      "Dataset: imagenet-21k\n",
      "Dataset: imagenet-22k\n",
      "Dataset: imagenet_1k\n",
      "Dataset: imagewoof\n",
      "Dataset: indian_food_images\n",
      "Dataset: indoor-scene-classification\n",
      "Dataset: keremberke/pokemon-classification\n",
      "Dataset: lewtun/dog_food\n",
      "Dataset: mnist\n",
      "Dataset: mriDataSet\n",
      "Dataset: nctcrche100_k\n",
      "Dataset: painting-style-classification\n",
      "Dataset: plankton_fairscope\n",
      "Dataset: pokemon-classification\n",
      "Dataset: preprocessed1024_config\n",
      "Dataset: private crawled images\n",
      "Dataset: renovations\n",
      "Dataset: rock-glacier-dataset\n",
      "Dataset: rokmr/pets\n",
      "Dataset: rvl_cdip\n",
      "Dataset: sasha/dog-food\n",
      "Dataset: shoe-classification\n",
      "Dataset: smokedataset\n",
      "Dataset: snacks\n",
      "Dataset: stool-image\n",
      "Dataset: touchtech/fashion-images-gender-age\n",
      "Dataset: touchtech/fashion-images-pack-types\n",
      "Dataset: touchtech/fashion-images-perspectives\n",
      "Dataset: trees\n",
      "Dataset: trpakov/chest-xray-classification\n",
      "Dataset: txoriak_txori\n",
      "Dataset: victor/autotrain-data-donut-vs-croissant\n",
      "Dataset: zindi\n",
      "Dataset: сhurch_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_dfs = {name: group.drop(columns='dataset') for name, group in df_explode.groupby('dataset')}\n",
    "\n",
    "count = 0\n",
    "for dataset_name, data in grouped_dfs.items():\n",
    "    count +=1\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheese = hf_api.list_models(author=\"hf-internal-testing\", cardData=True)\n",
    "cheese = [model for model in cheese]\n",
    "cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ModelCard.load(\"hf-internal-testing/tiny-random-vit\")\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
